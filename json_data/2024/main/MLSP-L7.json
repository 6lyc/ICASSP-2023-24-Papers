[
  {
    "title": "Defending against Clean-Image Backdoor Attack in Multi-Label Classification",
    "base_url": null,
    "title_page": null,
    "ieee_id": "10447895",
    "github": null,
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": null,
    "paper_arxiv_id": null,
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Adversarial Machine Learning"
  },
  {
    "title": "Robustness Against Adversarial Attacks Via Learning Confined Adversarial Polytopes",
    "base_url": null,
    "title_page": null,
    "ieee_id": "10446776",
    "github": null,
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": null,
    "paper_arxiv_id": "2401.07991",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Adversarial Machine Learning"
  },
  {
    "title": "SSTA: Salient Spatially Transformed Attack",
    "base_url": null,
    "title_page": null,
    "ieee_id": "10447882",
    "github": null,
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": null,
    "paper_arxiv_id": "2312.07258",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Adversarial Machine Learning"
  },
  {
    "title": "Enhancing Adversarial Transferability in Object Detection with Bidirectional Feature Distortion",
    "base_url": null,
    "title_page": null,
    "ieee_id": "10447293",
    "github": null,
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": null,
    "paper_arxiv_id": null,
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Adversarial Machine Learning"
  },
  {
    "title": "GCIA: A Black-Box Graph Injection Attack Method Via Graph Contrastive Learning",
    "base_url": null,
    "title_page": null,
    "ieee_id": "10446876",
    "github": "Gmrider13/GCIA",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": null,
    "paper_arxiv_id": null,
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Adversarial Machine Learning"
  },
  {
    "title": "Towards a Unified View of Adversarial Training: A Contrastive Perspective",
    "base_url": null,
    "title_page": null,
    "ieee_id": "10446746",
    "github": null,
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": null,
    "paper_arxiv_id": null,
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Adversarial Machine Learning"
  },
  {
    "title": "MEAT: Median-Ensemble Adversarial Training for Improving Robustness and Generalization",
    "base_url": null,
    "title_page": null,
    "ieee_id": "10446117",
    "github": null,
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": null,
    "paper_arxiv_id": null,
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Adversarial Machine Learning"
  },
  {
    "title": "Architecture-Agnostic Iterative Black-Box Certified Defense Against Adversarial Patches",
    "base_url": null,
    "title_page": null,
    "ieee_id": "10448145",
    "github": null,
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": null,
    "paper_arxiv_id": "2305.10929",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Adversarial Machine Learning"
  },
  {
    "title": "OADAS: Optimizing Global Perturbation Attacks with Dual-Path Attribution Synergy",
    "base_url": null,
    "title_page": null,
    "ieee_id": "10446681",
    "github": null,
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": null,
    "paper_arxiv_id": null,
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Adversarial Machine Learning"
  },
  {
    "title": "Towards Video-Text Retrieval Adversarial Attack",
    "base_url": null,
    "title_page": null,
    "ieee_id": "10448358",
    "github": null,
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": null,
    "paper_arxiv_id": null,
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Adversarial Machine Learning"
  },
  {
    "title": "FIBA: Federated Invisible Backdoor Attack",
    "base_url": null,
    "title_page": null,
    "ieee_id": "10446910",
    "github": null,
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": null,
    "paper_arxiv_id": null,
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Adversarial Machine Learning"
  },
  {
    "title": "Identifying Attack-Specific Signatures in Adversarial Examples",
    "base_url": null,
    "title_page": null,
    "ieee_id": "10446989",
    "github": "hsouri/REDRL",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": null,
    "paper_arxiv_id": "2110.06802",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Adversarial Machine Learning"
  },
  {
    "title": "Ten-Guard: Tensor Decomposition for Backdoor Attack Detection in Deep Neural Networks",
    "base_url": null,
    "title_page": null,
    "ieee_id": "10448222",
    "github": null,
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": null,
    "paper_arxiv_id": "2401.05432",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Adversarial Machine Learning"
  },
  {
    "title": "Language Guided Adversarial Purification",
    "base_url": null,
    "title_page": null,
    "ieee_id": "10446676",
    "github": "Visual-Conception-Group/LGAP",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": null,
    "paper_arxiv_id": "2309.10348",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Adversarial Machine Learning"
  },
  {
    "title": "Image Mixing and Gradient Smoothing to Enhance the SAR Image Attack Transferability",
    "base_url": null,
    "title_page": null,
    "ieee_id": "10448395",
    "github": "JHL-HUST/IMGS",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": null,
    "paper_arxiv_id": null,
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Adversarial Machine Learning"
  },
  {
    "title": "PoisonPrompt: Backdoor Attack on Prompt-Based Large Language Models",
    "base_url": null,
    "title_page": null,
    "ieee_id": "10446267",
    "github": null,
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": null,
    "paper_arxiv_id": "2310.12439",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Adversarial Machine Learning"
  }
]