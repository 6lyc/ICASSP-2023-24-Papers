# ICASSP-2024-Papers

<table>
    <tr>
        <td><strong>Application</strong></td>
        <td>
            <a href="https://huggingface.co/spaces/DmitryRyumin/NewEraAI-Papers" style="float:left;">
                <img src="https://img.shields.io/badge/ðŸ¤—-NewEraAI--Papers-FFD21F.svg" alt="App" />
            </a>
        </td>
    </tr>
    <tr>
        <td><strong>Previous Collections</strong></td>
        <td>
            <a href="https://github.com/DmitryRyumin/ICASSP-2023-24-Papers/blob/main/README_2023.md">
                <img src="http://img.shields.io/badge/ICASSP-2023-0073AE.svg" alt="Conference">
            </a>
        </td>
    </tr>
</table>

<div align="center">
    <a href="https://github.com/DmitryRyumin/ICASSP-2023-24-Papers/blob/main/sections/2024/main/MLSP-P24.md">
        <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/left.svg" width="40" alt="" />
    </a>
    <a href="https://github.com/DmitryRyumin/ICASSP-2023-24-Papers/">
        <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/home.svg" width="40" alt="" />
    </a>
    <a href="https://github.com/DmitryRyumin/ICASSP-2023-24-Papers/blob/main/sections/2024/main/SLP-P21.md">
        <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/right.svg" width="40" alt="" />
    </a>
</div>


## Human-Centric Multimedia

![Section Papers](https://img.shields.io/badge/Section%20Papers-10-42BA16) ![Preprint Papers](https://img.shields.io/badge/Preprint%20Papers-8-b31b1b) ![Papers with Open Code](https://img.shields.io/badge/Papers%20with%20Open%20Code-2-1D7FBF) ![Papers with Video](https://img.shields.io/badge/Papers%20with%20Video-0-FF0000)

| **Title** | **Repo** | **Paper** | **Video** |
|-----------|:--------:|:---------:|:---------:|
| Freetalker: Controllable Speech and Text-Driven Gesture Generation Based on Diffusion Models for Enhanced Speaker Naturalness | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg?style=flat)](https://youngseng.github.io/FreeTalker/) <br /> [![GitHub](https://img.shields.io/github/stars/YoungSeng/FreeTalker?style=flat)](https://github.com/YoungSeng/FreeTalker/) | [![IEEE Xplore](https://img.shields.io/badge/IEEE-10447978-E4A42C.svg)](https://ieeexplore.ieee.org/document/10447978) <br/> [![arXiv](https://img.shields.io/badge/arXiv-2401.03476-b31b1b.svg)](https://arxiv.org/abs/2401.03476) | :heavy_minus_sign: |
| Enhancing Expressiveness in Dance Generation via Integrating Frequency and Music Style Information | [![GitHub](https://img.shields.io/github/stars/thuhcsi/ExpressiveBailando?style=flat)](https://github.com/thuhcsi/ExpressiveBailando) | [![IEEE Xplore](https://img.shields.io/badge/IEEE-10448469-E4A42C.svg)](https://ieeexplore.ieee.org/document/10448469) <br/> [![arXiv](https://img.shields.io/badge/arXiv-2403.05834-b31b1b.svg)](https://arxiv.org/abs/2403.05834) | :heavy_minus_sign: |
| Modality Dropout for Multimodal Device Directed Speech Detection using Verbal and Non-Verbal Features | :heavy_minus_sign: | [![IEEE Xplore](https://img.shields.io/badge/IEEE-10446421-E4A42C.svg)](https://ieeexplore.ieee.org/document/10446421) <br/> [![arXiv](https://img.shields.io/badge/arXiv-2310.15261-b31b1b.svg)](http://arxiv.org/abs/2310.15261) | :heavy_minus_sign: |
| Audio-Visual Child-Adult Speaker Classification in Dyadic Interactions | :heavy_minus_sign: | [![IEEE Xplore](https://img.shields.io/badge/IEEE-10447515-E4A42C.svg)](https://ieeexplore.ieee.org/document/10447515) <br/> [![arXiv](https://img.shields.io/badge/arXiv-2310.01867-b31b1b.svg)](https://arxiv.org/abs/2310.01867) | :heavy_minus_sign: |
| Long-Term Social Interaction Context: The Key to Egocentric Addressee Detection | :heavy_minus_sign: | [![IEEE Xplore](https://img.shields.io/badge/IEEE-10447323-E4A42C.svg)](https://ieeexplore.ieee.org/document/10447323) | :heavy_minus_sign: |
| AutoSen: Improving Automatic WiFi Human Sensing through Cross-Modal Autoencoder | :heavy_minus_sign: | [![IEEE Xplore](https://img.shields.io/badge/IEEE-10446641-E4A42C.svg)](https://ieeexplore.ieee.org/document/10446641) <br/> [![arXiv](https://img.shields.io/badge/arXiv-2401.05440-b31b1b.svg)](https://arxiv.org/abs/2401.05440) | :heavy_minus_sign: |
| Facial Micro-Motion-Aware Mixup for Micro-Expression Recognition | :heavy_minus_sign: | [![IEEE Xplore](https://img.shields.io/badge/IEEE-10446492-E4A42C.svg)](https://ieeexplore.ieee.org/document/10446492) | :heavy_minus_sign: |
| MMBaT: A Multi-task Framework for mmWave-based Human Body Reconstruction and Translation Prediction | :heavy_minus_sign: | [![IEEE Xplore](https://img.shields.io/badge/IEEE-10448164-E4A42C.svg)](https://ieeexplore.ieee.org/document/10448164) <br/> [![arXiv](https://img.shields.io/badge/arXiv-2312.10346-b31b1b.svg)](https://arxiv.org/abs/2312.10346) | :heavy_minus_sign: |
| Exploring Multi-Modal Control in Music-Driven Dance Generation | :heavy_minus_sign: | [![IEEE Xplore](https://img.shields.io/badge/IEEE-10447825-E4A42C.svg)](https://ieeexplore.ieee.org/document/10447825) <br/> [![arXiv](https://img.shields.io/badge/arXiv-2401.01382-b31b1b.svg)](https://arxiv.org/abs/2401.01382) | :heavy_minus_sign: |
| Conversational Co-Speech Gesture Generation via Modeling Dialog Intention, Emotion, and Context with Diffusion Models | :heavy_minus_sign: | [![IEEE Xplore](https://img.shields.io/badge/IEEE-10448208-E4A42C.svg)](https://ieeexplore.ieee.org/document/10448208) <br/> [![arXiv](https://img.shields.io/badge/arXiv-2312.15567-b31b1b.svg)](https://arxiv.org/abs/2312.15567) | :heavy_minus_sign: |