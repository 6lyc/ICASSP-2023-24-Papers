# ICASSP-2024-Papers

<table>
    <tr>
        <td><strong>Application</strong></td>
        <td>
            <a href="https://huggingface.co/spaces/DmitryRyumin/NewEraAI-Papers" style="float:left;">
                <img src="https://img.shields.io/badge/ðŸ¤—-NewEraAI--Papers-FFD21F.svg" alt="App" />
            </a>
        </td>
    </tr>
    <tr>
        <td><strong>Previous Collections</strong></td>
        <td>
            <a href="https://github.com/DmitryRyumin/ICASSP-2023-24-Papers/blob/main/README_2023.md">
                <img src="http://img.shields.io/badge/ICASSP-2023-0073AE.svg" alt="Conference">
            </a>
        </td>
    </tr>
</table>

<div align="center">
    <a href="https://github.com/DmitryRyumin/ICASSP-2023-24-Papers/blob/main/sections/2024/main/BISP-P5.md">
        <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/left.svg" width="40" alt="" />
    </a>
    <a href="https://github.com/DmitryRyumin/ICASSP-2023-24-Papers/">
        <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/home.svg" width="40" alt="" />
    </a>
    <a href="https://github.com/DmitryRyumin/ICASSP-2023-24-Papers/blob/main/sections/2024/main/AASP-L4.md">
        <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/right.svg" width="40" alt="" />
    </a>
</div>

## Text to Speech Generation

![Section Papers](https://img.shields.io/badge/Section%20Papers-12-42BA16) ![Preprint Papers](https://img.shields.io/badge/Preprint%20Papers-12-b31b1b) ![Papers with Open Code](https://img.shields.io/badge/Papers%20with%20Open%20Code-5-1D7FBF) ![Papers with Video](https://img.shields.io/badge/Papers%20with%20Video-0-FF0000)

| **Title** | **Repo** | **Paper** | **Video** |
|-----------|:--------:|:---------:|:---------:|
| Creating Personalized Synthetic Voices from Articulation Impaired Speech using Augmented Reconstruction Loss | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://myspeechproject.github.io/ArticulationRepair/) | [![IEEE Xplore](https://img.shields.io/badge/IEEE-10446886-E4A42C.svg)](https://ieeexplore.ieee.org/document/10446886) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2401.03816-b31b1b.svg)](https://arxiv.org/abs/2401.03816) | :heavy_minus_sign: |
| VoiceFlow: Efficient Text-to-Speech with Rectified Flow Matching | [![GitHub](https://img.shields.io/github/stars/X-LANCE/VoiceFlow-TTS?style=flat)](https://github.com/X-LANCE/VoiceFlow-TTS) | [![IEEE Xplore](https://img.shields.io/badge/IEEE-10445948-E4A42C.svg)](https://ieeexplore.ieee.org/document/10445948) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2309.05027-b31b1b.svg)](https://arxiv.org/abs/2309.05027) | :heavy_minus_sign: |
| Matcha-TTS: A Fast TTS Architecture with Conditional Flow Matching | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://shivammehta25.github.io/Matcha-TTS/) <br /> [![GitHub](https://img.shields.io/github/stars/shivammehta25/Matcha-TTS?style=flat)](https://github.com/shivammehta25/Matcha-TTS) | [![IEEE Xplore](https://img.shields.io/badge/IEEE-10448291-E4A42C.svg)](https://ieeexplore.ieee.org/document/10448291) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2309.03199-b31b1b.svg)](https://arxiv.org/abs/2309.03199) | :heavy_minus_sign: |
| Extending Multilingual Speech Synthesis to 100+ Languages without Transcribed Data | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://google.github.io/tacotron/publications/extending_tts/) | [![IEEE Xplore](https://img.shields.io/badge/IEEE-10448074-E4A42C.svg)](https://ieeexplore.ieee.org/document/10448074) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2402.18932-b31b1b.svg)](https://arxiv.org/abs/2402.18932) | :heavy_minus_sign: |
| PromptTTS++: Controlling Speaker Identity in Prompt-Based Text-to-Speech using Natural Language Descriptions | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://reppy4620.github.io/demo.promptttspp/) | [![IEEE Xplore](https://img.shields.io/badge/IEEE-10448173-E4A42C.svg)](https://ieeexplore.ieee.org/document/10448173) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2309.08140-b31b1b.svg)](https://arxiv.org/abs/2309.08140) | :heavy_minus_sign: |
| VoiceLDM: Text-to-Speech with Environmental Context | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://voiceldm.github.io/) <br /> [![GitHub](https://img.shields.io/github/stars/glory20h/VoiceLDM?style=flat)](https://github.com/glory20h/VoiceLDM) | [![IEEE Xplore](https://img.shields.io/badge/IEEE-10448268-E4A42C.svg)](https://ieeexplore.ieee.org/document/10448268) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2309.13664-b31b1b.svg)](https://arxiv.org/abs/2309.13664) | :heavy_minus_sign: |
| DETS: End-to-End Single-Stage Text-to-Speech via Hierarchical Diffusion Gan Models |  | [![IEEE Xplore](https://img.shields.io/badge/IEEE-10446855-E4A42C.svg)](https://ieeexplore.ieee.org/document/10446855) | :heavy_minus_sign: |
| Latent Filling: Latent Space Data Augmentation for Zero-Shot Speech Synthesis |  | [![IEEE Xplore](https://img.shields.io/badge/IEEE-10446098-E4A42C.svg)](https://ieeexplore.ieee.org/document/10446098) | :heavy_minus_sign: |
| An Experimental Comparison of Noise-Robust Text-to-Speech Synthesis Systems based On Self-Supervised Representation |  | [![IEEE Xplore](https://img.shields.io/badge/IEEE-10446750-E4A42C.svg)](https://ieeexplore.ieee.org/document/10446750) | :heavy_minus_sign: |
| Mels-TTS: Multi-Emotion Multi-Lingual Multi-Speaker Text-to-Speech System via Disentangled Style Tokens |  | [![IEEE Xplore](https://img.shields.io/badge/IEEE-10446852-E4A42C.svg)](https://ieeexplore.ieee.org/document/10446852) | :heavy_minus_sign: |
| Energy-based Models for Speech Synthesis |  | [![IEEE Xplore](https://img.shields.io/badge/IEEE-10447218-E4A42C.svg)](https://ieeexplore.ieee.org/document/10447218) | :heavy_minus_sign: |
| Improving Language Model-based Zero-Shot Text-to-Speech Synthesis with Multi-Scale Acoustic Prompts |  | [![IEEE Xplore](https://img.shields.io/badge/IEEE-10447815-E4A42C.svg)](https://ieeexplore.ieee.org/document/10447815) | :heavy_minus_sign: |
| Minimally-Supervised Speech Synthesis with Conditional Diffusion Model and Language Model: A Comparative Study of Semantic Coding |  | [![IEEE Xplore](https://img.shields.io/badge/IEEE-10446203-E4A42C.svg)](https://ieeexplore.ieee.org/document/10446203) | :heavy_minus_sign: |
| High-Fidelity Speech Synthesis with Minimal Supervision: All using Diffusion Models |  | [![IEEE Xplore](https://img.shields.io/badge/IEEE-10448495-E4A42C.svg)](https://ieeexplore.ieee.org/document/10448495) | :heavy_minus_sign: |
| Reflow-TTS: A Rectified Flow Model for High-Fidelity Text-to-Speech |  | [![IEEE Xplore](https://img.shields.io/badge/IEEE-10447822-E4A42C.svg)](https://ieeexplore.ieee.org/document/10447822) | :heavy_minus_sign: |
| Adversarial Learning on Compressed Posterior Space for Non-Iterative Score-based End-to-End Text-to-Speech |  | [![IEEE Xplore](https://img.shields.io/badge/IEEE-10446958-E4A42C.svg)](https://ieeexplore.ieee.org/document/10446958) | :heavy_minus_sign: |
| DCTTS: Discrete Diffusion Model with Contrastive Learning for Text-to-Speech Generation |  | [![IEEE Xplore](https://img.shields.io/badge/IEEE-10447661-E4A42C.svg)](https://ieeexplore.ieee.org/document/10447661) | :heavy_minus_sign: |
| Enhancing Multilingual TTS with Voice Conversion based Data Augmentation and Posterior Embedding |  | [![IEEE Xplore](https://img.shields.io/badge/IEEE-10448471-E4A42C.svg)](https://ieeexplore.ieee.org/document/10448471) | :heavy_minus_sign: |
| Ultra-Lightweight Neural Differential DSP Vocoder for High Quality Speech Synthesis | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://ddsp-vocoder.github.io/ddsp/) | [![IEEE Xplore](https://img.shields.io/badge/IEEE-10447948-E4A42C.svg)](https://ieeexplore.ieee.org/document/10447948) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2401.10460-b31b1b.svg)](https://arxiv.org/abs/2401.10460) | :heavy_minus_sign: |
| Fregrad: Lightweight and Fast Frequency-Aware Diffusion Vocoder | [![WEB Page](https://img.shields.io/badge/WEB-Page-159957.svg)](https://mm.kaist.ac.kr/projects/FreGrad) | [![IEEE Xplore](https://img.shields.io/badge/IEEE-10447251-E4A42C.svg)](https://ieeexplore.ieee.org/document/10447251) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2401.10032-b31b1b.svg)](https://arxiv.org/abs/2401.10032) | :heavy_minus_sign: |
| BIGVSAN: Enhancing Gan-based Neural Vocoders with Slicing Adversarial Network | [![GitHub](https://img.shields.io/github/stars/sony/bigvsan?style=flat)](https://github.com/sony/bigvsan) | [![IEEE Xplore](https://img.shields.io/badge/IEEE-10446121-E4A42C.svg)](https://ieeexplore.ieee.org/document/10446121) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2309.02836-b31b1b.svg)](https://arxiv.org/abs/2309.02836) | :heavy_minus_sign: |
| Noise-Robust Zero-Shot Text-to-Speech Synthesis Conditioned on Self-Supervised Speech-Representation Model with Adapters | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://ntt-hilab-gensp.github.io/icassp2024robustTTS/) | [![IEEE Xplore](https://img.shields.io/badge/IEEE-10447809-E4A42C.svg)](https://ieeexplore.ieee.org/document/10447809) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2401.05111-b31b1b.svg)](https://arxiv.org/abs/2401.05111) | :heavy_minus_sign: |
| Speak While You Think: Streaming Speech Synthesis During Text Generation | :heavy_minus_sign: | [![IEEE Xplore](https://img.shields.io/badge/IEEE-10446214-E4A42C.svg)](https://ieeexplore.ieee.org/document/10446214) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2309.11210-b31b1b.svg)](https://arxiv.org/abs/2309.11210) | :heavy_minus_sign: |
| StoryTTS: A Highly Expressive Text-to-Speech Dataset with Rich Textual Expressiveness Annotations | [![GitHub](https://img.shields.io/github/stars/X-LANCE/StoryTTS?style=flat)](https://github.com/X-LANCE/StoryTTS) | [![IEEE Xplore](https://img.shields.io/badge/IEEE-10446023-E4A42C.svg)](https://ieeexplore.ieee.org/document/10446023) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2404.14946-b31b1b.svg)](https://arxiv.org/abs/2404.14946) | :heavy_minus_sign: |
| GLA-GRAD: A Griffin-Lim Extended Waveform Generation Diffusion Model |  | [![IEEE Xplore](https://img.shields.io/badge/IEEE-10446058-E4A42C.svg)](https://ieeexplore.ieee.org/document/10446058) | :heavy_minus_sign: |
| Training Generative Adversarial Network-based Vocoder with Limited Data using Augmentation-Conditional Discriminator |  | [![IEEE Xplore](https://img.shields.io/badge/IEEE-10445914-E4A42C.svg)](https://ieeexplore.ieee.org/document/10445914) | :heavy_minus_sign: |
| PeriodGrad: Towards Pitch-Controllable Neural Vocoder based on a Diffusion Probabilistic Model |  | [![IEEE Xplore](https://img.shields.io/badge/IEEE-10448502-E4A42C.svg)](https://ieeexplore.ieee.org/document/10448502) | :heavy_minus_sign: |
| ED-TTS: Multi-Scale Emotion Modeling using Cross-Domain Emotion Diarization for Emotional Speech Synthesis |  | [![IEEE Xplore](https://img.shields.io/badge/IEEE-10446467-E4A42C.svg)](https://ieeexplore.ieee.org/document/10446467) | :heavy_minus_sign: |
| Considering Temporal Connection between Turns for Conversational Speech Synthesis |  | [![IEEE Xplore](https://img.shields.io/badge/IEEE-10448356-E4A42C.svg)](https://ieeexplore.ieee.org/document/10448356) | :heavy_minus_sign: |
| Hierarchical Emotion Prediction and Control in Text-to-Speech Synthesis |  | [![IEEE Xplore](https://img.shields.io/badge/IEEE-10445996-E4A42C.svg)](https://ieeexplore.ieee.org/document/10445996) | :heavy_minus_sign: |
| Controllable Speaking Styles using A Large Language Model |  | [![IEEE Xplore](https://img.shields.io/badge/IEEE-10448400-E4A42C.svg)](https://ieeexplore.ieee.org/document/10448400) | :heavy_minus_sign: |
| Concss: Contrastive-based Context Comprehension for Dialogue-Appropriate Prosody in Conversational Speech Synthesis |  | [![IEEE Xplore](https://img.shields.io/badge/IEEE-10446506-E4A42C.svg)](https://ieeexplore.ieee.org/document/10446506) | :heavy_minus_sign: |
| Spontts: Modeling and Transferring Spontaneous Style for TTS |  | [![IEEE Xplore](https://img.shields.io/badge/IEEE-10445828-E4A42C.svg)](https://ieeexplore.ieee.org/document/10445828) | :heavy_minus_sign: |
| Controllable Prosody Generation with Partial Inputs |  | [![IEEE Xplore](https://img.shields.io/badge/IEEE-10446859-E4A42C.svg)](https://ieeexplore.ieee.org/document/10446859) | :heavy_minus_sign: |
| Stylespeech: Self-Supervised Style Enhancing with VQ-VAE-based Pre-Training for Expressive Audiobook Speech Synthesis |  | [![IEEE Xplore](https://img.shields.io/badge/IEEE-10446352-E4A42C.svg)](https://ieeexplore.ieee.org/document/10446352) | :heavy_minus_sign: |
| TNFormer: Single-Pass Multilingual Text Normalization with a Transformer Decoder Model |  | [![IEEE Xplore](https://img.shields.io/badge/IEEE-10446848-E4A42C.svg)](https://ieeexplore.ieee.org/document/10446848) | :heavy_minus_sign: |
| A Unified Front-End Framework for English Text-to-Speech Synthesis |  | [![IEEE Xplore](https://img.shields.io/badge/IEEE-10447144-E4A42C.svg)](https://ieeexplore.ieee.org/document/10447144) | :heavy_minus_sign: |
| Collaborative Watermarking for Adversarial Speech Synthesis |  | [![IEEE Xplore](https://img.shields.io/badge/IEEE-10448134-E4A42C.svg)](https://ieeexplore.ieee.org/document/10448134) | :heavy_minus_sign: |
| Mapache: Masked Parallel Transformer for Advanced Speech Editing and Synthesis |  | [![IEEE Xplore](https://img.shields.io/badge/IEEE-10448121-E4A42C.svg)](https://ieeexplore.ieee.org/document/10448121) | :heavy_minus_sign: |
| Diversity-based Core-Set Selection for Text-to-Speech with Linguistic and Acoustic Features |  | [![IEEE Xplore](https://img.shields.io/badge/IEEE-10448068-E4A42C.svg)](https://ieeexplore.ieee.org/document/10448068) | :heavy_minus_sign: |
| Fewer-Token Neural Speech Codec with Time-Invariant Codes |  | [![IEEE Xplore](https://img.shields.io/badge/IEEE-10448454-E4A42C.svg)](https://ieeexplore.ieee.org/document/10448454) | :heavy_minus_sign: |
| Convnext-TTS and Convnext-VC: Convnext-based Fast End-to-End Sequence-to-Sequence Text-to-Speech and Voice Conversion |  | [![IEEE Xplore](https://img.shields.io/badge/IEEE-10446890-E4A42C.svg)](https://ieeexplore.ieee.org/document/10446890) | :heavy_minus_sign: |
| SYNTHE-SEES: Face based Text-to-Speech for Virtual Speaker |  | [![IEEE Xplore](https://img.shields.io/badge/IEEE-10448433-E4A42C.svg)](https://ieeexplore.ieee.org/document/10448433) | :heavy_minus_sign: |
| Language-Oriented Communication with Semantic Coding and Knowledge Distillation for Text-to-Image Generation |  | [![IEEE Xplore](https://img.shields.io/badge/IEEE-10446638-E4A42C.svg)](https://ieeexplore.ieee.org/document/10446638) | :heavy_minus_sign: |
