# ICASSP-2024-Papers

<table>
    <tr>
        <td><strong>Application</strong></td>
        <td>
            <a href="https://huggingface.co/spaces/DmitryRyumin/NewEraAI-Papers" style="float:left;">
                <img src="https://img.shields.io/badge/ðŸ¤—-NewEraAI--Papers-FFD21F.svg" alt="App" />
            </a>
        </td>
    </tr>
    <tr>
        <td><strong>Previous Collections</strong></td>
        <td>
            <a href="https://github.com/DmitryRyumin/ICASSP-2023-24-Papers/blob/main/README_2023.md">
                <img src="http://img.shields.io/badge/ICASSP-2023-0073AE.svg" alt="Conference">
            </a>
        </td>
    </tr>
</table>

<div align="center">
    <a href="https://github.com/DmitryRyumin/ICASSP-2023-24-Papers/blob/main/sections/2024/main/MLSP-P22.md">
        <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/left.svg" width="40" alt="" />
    </a>
    <a href="https://github.com/DmitryRyumin/ICASSP-2023-24-Papers/">
        <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/home.svg" width="40" alt="" />
    </a>
    <a href="https://github.com/DmitryRyumin/ICASSP-2023-24-Papers/blob/main/sections/2024/main/MLSP-P23.md">
        <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/right.svg" width="40" alt="" />
    </a>
</div>


## Speaker Recognition and Anonymization

![Section Papers](https://img.shields.io/badge/Section%20Papers-13-42BA16) ![Preprint Papers](https://img.shields.io/badge/Preprint%20Papers-8-b31b1b) ![Papers with Open Code](https://img.shields.io/badge/Papers%20with%20Open%20Code-0-1D7FBF) ![Papers with Video](https://img.shields.io/badge/Papers%20with%20Video-0-FF0000)

| **Title** | **Repo** | **Paper** | **Video** |
|-----------|:--------:|:---------:|:---------:|
| Multi-View Speaker Embedding Learning for Enhanced Stability and Discriminability | :heavy_minus_sign: | [![IEEE Xplore](https://img.shields.io/badge/IEEE-10448494-E4A42C.svg)](https://ieeexplore.ieee.org/document/10448494) | :heavy_minus_sign: |
| What Do Self-Supervised Speech and Speaker Models Learn? New Findings From a Cross Model Layer-Wise Analysis | :heavy_minus_sign: | [![IEEE Xplore](https://img.shields.io/badge/IEEE-10446422-E4A42C.svg)](https://ieeexplore.ieee.org/document/10446422) <br/> [![arXiv](https://img.shields.io/badge/arXiv-2401.17632-b31b1b.svg)](https://arxiv.org/abs/2401.17632) | :heavy_minus_sign: |
| A Speaker Recognition Method Based on Stable Learning | :heavy_minus_sign: | [![IEEE Xplore](https://img.shields.io/badge/IEEE-10446329-E4A42C.svg)](https://ieeexplore.ieee.org/document/10446329) | :heavy_minus_sign: |
| Generating High-Quality Adversarial Examples with Universal Perturbation-Based Adaptive Network and Improved Perceptual Loss | :heavy_minus_sign: | [![IEEE Xplore](https://img.shields.io/badge/IEEE-10446184-E4A42C.svg)](https://ieeexplore.ieee.org/document/10446184) | :heavy_minus_sign: |
| A Study on Graph Embedding for Speaker Recognition | :heavy_minus_sign: | [![IEEE Xplore](https://img.shields.io/badge/IEEE-10448308-E4A42C.svg)](https://ieeexplore.ieee.org/document/10448308) | :heavy_minus_sign: |
| Post-Training Embedding Alignment for Decoupling Enrollment and Runtime Speaker Recognition Models | :heavy_minus_sign: | [![IEEE Xplore](https://img.shields.io/badge/IEEE-10447161-E4A42C.svg)](https://ieeexplore.ieee.org/document/10447161) <br/> [![arXiv](https://img.shields.io/badge/arXiv-2401.12440-b31b1b.svg)](https://arxiv.org/abs/2401.12440) | :heavy_minus_sign: |
| Contrastive Speaker Embedding with Sequential Disentanglement | :heavy_minus_sign: | [![IEEE Xplore](https://img.shields.io/badge/IEEE-10448284-E4A42C.svg)](https://ieeexplore.ieee.org/document/10448284) <br/> [![arXiv](https://img.shields.io/badge/arXiv-2309.13253-b31b1b.svg)](https://arxiv.org/abs/2309.13253) | :heavy_minus_sign: |
| Leveraging In-the-Wild Data for Effective Self-Supervised Pretraining in Speaker Recognition | :heavy_minus_sign: | [![IEEE Xplore](https://img.shields.io/badge/IEEE-10447489-E4A42C.svg)](https://ieeexplore.ieee.org/document/10447489) <br/> [![arXiv](https://img.shields.io/badge/arXiv-2309.11730-b31b1b.svg)](https://arxiv.org/abs/2309.11730) | :heavy_minus_sign: |
| SynVox2: Towards a privacy-friendly VoxCeleb2 dataset | :heavy_minus_sign: | [![IEEE Xplore](https://img.shields.io/badge/IEEE-10446513-E4A42C.svg)](https://ieeexplore.ieee.org/document/10446513) <br/> [![arXiv](https://img.shields.io/badge/arXiv-2309.06141-b31b1b.svg)](https://arxiv.org/abs/2309.06141) | :heavy_minus_sign: |
| An Investigation of Distribution Alignment in Multi-Genre Speaker Recognition | :heavy_minus_sign: | [![IEEE Xplore](https://img.shields.io/badge/IEEE-10448178-E4A42C.svg)](https://ieeexplore.ieee.org/document/10448178) <br/> [![arXiv](https://img.shields.io/badge/arXiv-2309.14158-b31b1b.svg)](https://arxiv.org/abs/2309.14158) | :heavy_minus_sign: |
| Discrete Audio Representation as an Alternative to Mel-Spectrograms for Speaker and Speech Recognition | :heavy_minus_sign: | [![IEEE Xplore](https://img.shields.io/badge/IEEE-10446998-E4A42C.svg)](https://ieeexplore.ieee.org/document/10446998) <br/> [![arXiv](https://img.shields.io/badge/arXiv-2309.10922-b31b1b.svg)](https://arxiv.org/abs/2309.10922) | :heavy_minus_sign: |
| Modeling Pseudo-Speaker Uncertainty in Voice Anonymization | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg?style=flat)](https://voiceprivacy.github.io/pseudo-speaker-vector/) | [![IEEE Xplore](https://img.shields.io/badge/IEEE-10446573-E4A42C.svg)](https://ieeexplore.ieee.org/document/10446573) | :heavy_minus_sign: |
| Speaker Anonymization Using Orthogonal Householder Neural Network | :heavy_minus_sign: | [![IEEE Xplore](https://img.shields.io/badge/IEEE-10244064-E4A42C.svg)](https://ieeexplore.ieee.org/document/10244064) <br/> [![arXiv](https://img.shields.io/badge/arXiv-2305.18823-b31b1b.svg)](https://arxiv.org/abs/2305.18823) | :heavy_minus_sign: |
